Face Recognition and Classification with Eigenfaces 
Emma DaPonte

    For this project, a large number of celebrity pictures were downloaded, cropped to just the faces, resized to 32 x 32 pixels, divided into 3 sets of images (training, validation, and test), and then the validation images were matched to images in the training set using principle component analysis. The success of these matchings was used to fine tune parameters, which were then applied to matching the test set to the training set images.

    Within the given data set of celebrity pictures, there was included coordinates corresponding to a bounding box for where to crop the face. The given bounding boxes were mostly accurate, but did cut off parts of the face in some cases, usually the bottom of the chin or top of the forehead. Some cropped out faces could be aligned with each other, but on the whole, it would be difficult due to faces being in profile or tilted, faces taking up more or less of the bounding box than others, and bounding boxes not exactly capturing the face (sometimes cutting it off, and sometimes including the background image in the case of profiled faces). Some images in the dataset were downloaded from different sources but remarkably similar. Overall the quality of the data was good and lead to decent face matching results.

    To perform facial recognition as instructed, the dataset must be separated into the training set, the validation set, and the test set. To separate the dataset into three non-overlapping parts, I simply iterated through every cropped and resized file using python, and put the first 100 I found into the training set, the next ten into the validation set, and the last ten into the test set. Since python doesn't read the images in the file in alphabetical order, this method was slightly more randomized than if the same thing had been done by hand. 
    
    When matching the validation set for actor name, the highest accuracy achieved was 65 percent, with 52 matches and 38 fails, found by projecting the validation image on the first 100 eigenfaces. When attempting to match the test set's name using 100 eigenfaces, the percentage correct dropped to 58.75, with 47 matches and 33 fails.  

    Matching for gender produced much higher results. When matching the validation set's gender, the highest accuracy was 91.125 percent, with 73 matches and 7 fails for projecting the validation image on the first 150 eigenfaces (though using 200 eigenfaces produced the same result). When attempting to match the test set's gender using 150 eigenfaces, the percentage correct dropped to 86.25, with 69 matches and 11 fails.
